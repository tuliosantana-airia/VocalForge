{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refining Raw Audio\n",
    "\n",
    "In this tutorial, you will learn how to apply `VocalForge.audio` pipelines on audio files.\n",
    "\n",
    "Each pipeline will (or at least attempt to) remove poor/inappropiate audio from each file in order to better prime it for dataset creation, or whatever other purpose you have in mind. These can be done in different order, or some not at all. It's up to you!\n",
    "\n",
    "The models generally consist of a neural network designed to identify a specific piece of audio, then mark timestamps for its removal. Let's go over the ones currently supported in order to better illistrates VocalForge's usefulness:\n",
    "\n",
    "- `Voice Detection` will remove segments of audio in which no human sounds are found. Say there is a long segment of city noise, or a musical intro to a podcast, all of this is removed. This is helpful not only in that it removes any of that non human audio, but it also reduces the time in which the subsequent audio takes to process.\n",
    "\n",
    "- `Overlap` covers speech that has two or more people talking at the same time. Not only does it forceably remove egotistical people from trying to take over a conversation, but it *also* removes poor audio from podcasts or other casual conversational settings.\n",
    "\n",
    "- `Isolate` one of the less straightforward pipelines, it goes through and seperates each speaker in each audio file. From there, you as a user can specify a specific speaker you want to target and it will find that same user across each audio file, even in different recording enviroments, such as a recording studio and a park. \n",
    "\n",
    "- `Export` is really just to put everything in a nice little bow. Given a directory, it will format on sample rate, as well as optionally normalize and noise reduce the audio. \n",
    "\n",
    "More pipelines are coming soonâ„¢"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: It is highly reccomended to run this on a conda enviroment if running locally by running the command\n",
    "`conda create -n VocalForge python=3.8 pytorch=1.11.0 torchvision=0.12.0 torchaudio=0.11.0 cudatoolkit=11.3.1 -c pytorch`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get to creating our work directory and installing `VocalForge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root_path = Path.cwd()  # Gets current working directory\n",
    "print(root_path)\n",
    "\n",
    "work_audio_path = root_path / 'work' / 'audio'  # Constructs a new path\n",
    "\n",
    "work_audio_path.mkdir(parents=True, exist_ok=True)  # Creates all missing parents in the path (does not raise any exceptions if the directory already exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VocalForge.audio.audio_utils import create_core_folders\n",
    "\n",
    "root_path = Path.cwd()\n",
    "work_audio_path = root_path / 'work' / 'audio'\n",
    "\n",
    "folder_names = ['RawAudio', 'Samples', 'VD', 'Overlap', 'Verification',\n",
    "                'Isolated', 'Exported', 'Noise_Removed', 'Normalized']\n",
    "\n",
    "# Here, we pass the folder paths to 'create_core_folders' method as string instead of 'os.path.join'\n",
    "create_core_folders(folder_names, workdir=str(work_audio_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright cool, thats all taken care of. Now for the sake of our demo, we will download a YouTube Playlist of Joe Biden, however you could link your own playlist or simply drop your own local wav files into the `RawAudio` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VocalForge.audio.audio_utils import download_videos\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "download_videos(\n",
    "    url='https://www.youtube.com/playlist?list=PLAVNH_8nglubKvZ8bdiEjf9IKKB73SvIy', \n",
    "    out_dir=str(work_path / 'RawAudio')\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For actual production, we would want to process all the audio we can get our grubby hands on. But for the purposes of our demo, we will be trimming each audio down to 5 minutes using the `create_samples` method  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VocalForge.audio.audio_utils import create_samples\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "create_samples(\n",
    "    length=300,\n",
    "    input_dir=str(work_path / 'RawAudio'),\n",
    "    output_dir=str(work_path / 'Samples'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "Audio(str(work_path / 'Samples' / 'DATA0.wav'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voice Activity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the class and set the paths of what the input files are, and where to output the filtered files are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VocalForge.audio import VoiceDetection\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "VD = VoiceDetection(\n",
    "    input_dir=str(work_path / 'Samples'),\n",
    "    output_dir=str(work_path / 'VD'),\n",
    ")\n",
    "\n",
    "VD.run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Lets check out the timeline of an audio file to see what parts got deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VD.timelines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "Audio(str(work_path / 'VD' / 'DATA0.wav'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that the audio highlighted in red has too many short breaks which cause to abrupt cuts in the audio. we can change around some model parameters to change this. by modifying the `min_duration_off` and `min_duration_on` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HYPER_PARAMETERS = {\n",
    "  # onset/offset activation thresholds\n",
    "  \"onset\": 0.2, \"offset\": 0.6,\n",
    "  # remove speech regions shorter than that many seconds.\n",
    "  \"min_duration_on\": 1.0,\n",
    "  # fill non-speech regions shorter than that many seconds.\n",
    "  \"min_duration_off\": 1.0\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default values are normally:\n",
    "\n",
    "`Onset: 0.5`\n",
    "`Offset: 0.5`\n",
    "`min_duration_on: 0.0`\n",
    "`min_duration_off: 0.0`\n",
    "\n",
    "One can change any of these values to make the values a little more or less liberal in what is speech and what's not (see what I did there?). This can also be used for overlapping speech, however this feature does not exist for isolating voices."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlapping Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlap Detection\n",
    "from VocalForge.audio import Overlap\n",
    "\n",
    "OD = Overlap(\n",
    "    input_dir=str(work_path / 'VD'),\n",
    "    output_dir=str(work_path / 'Overlap')\n",
    ")\n",
    "OD.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD.timelines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "Audio(str(work_path / 'Overlap' / 'DATA0.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker Isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from VocalForge.audio.isolate import Isolate\n",
    "from pathlib import Path\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "IV = Isolate(\n",
    "    input_dir=str(work_path / 'Overlap'),\n",
    "    verification_dir=str(work_path / 'Verification'),  # this is where the separated voices will be saved\n",
    "    output_dir=str(work_path / 'Isolated'),  # this is where the targeted voice will be saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV.isolate_speakers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "Audio(str(work_path / 'Verification' / 'DATA0' / 'SPEAKER_00.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(str(work_path / 'Verification' / 'DATA0' / 'SPEAKER_01.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV.create_target_embedding(str(work_path / 'Verification' / 'DATA0' / 'SPEAKER_00.wav'), 'joe_biden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV.group_audios_by_speaker(threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "Audio(str(work_path / 'Isolated' / 'joe_biden' / 'DATA2_SPEAKER_01.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(str(work_path / 'Isolated' / 'joe_biden' / 'DATA4_SPEAKER_01.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(str(work_path / 'Isolated' / 'joe_biden' / 'DATA5_SPEAKER_00.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(str(work_path / 'Isolated' / 'joe_biden' / 'DATA6_SPEAKER_01.wav'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to export. This is how we can define the final output of the wav files. \n",
    "\n",
    "By declaring a directory to `noise_removed_dir` will apply deepfilternet2 to each audio file to reduce noise. I find that this specific NN works best compared to solutions like the Adobe Podcast Audio Upscaler for tasks like TTS training or some other application that requires natural audio processing.\n",
    "\n",
    "`normalization_dir`, if declared, will export a copy of the exported audio with normalized audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VocalForge.audio import ExportAudio\n",
    "from pathlib import Path\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "exported = ExportAudio(\n",
    "    input_dir=str(work_path / 'Isolated' / 'joe_biden'),\n",
    "    output_dir=str(work_path / 'Exported'),\n",
    "    noise_removed_dir=str(work_path / 'Noise_Removed'),\n",
    "    normalization_dir=str(work_path / 'Normalized'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported.noise_remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "work_path = Path.cwd() / 'work' / 'audio'\n",
    "\n",
    "Audio(str(work_path / 'Noise_Removed' / 'DATA0_SPEAKER_00.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported.create_samples(max_seconds=120)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you're done! Well, sort of. While this process does a pretty good job, to get the best results you will want to check the results manually. As I add more filters, this process will hopefully increase in resolution to reduce the time needed to review the output. But for now, stay vigilent.\n",
    "\n",
    "Next, we will be going over how to format this now refined audio into a dataset ready and prepped for a NN. Stay tuned!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vocalforge",
   "language": "python",
   "name": "vocalforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
